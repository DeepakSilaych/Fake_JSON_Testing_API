{
  "trending" :[
    {
      "id": 1,
      "name": "Transparent Image Layer Diffusion using Latent Transparency",
      "category": "Category 1",
      "shortdescription": "We show that latent transparency can be applied to different open source image generators, or be adapted to various conditional control systems to achieve applications like foreground/background-conditioned layer generation, joint layer generation, structural control of layer contents, etc.",
      "longdescription": "We present LayerDiffuse, an approach enabling large-scale pretrained latent diffusion models to generate transparent images. The method allows generation of single transparent images or of multiple transparent layers. The method learns a latent transparency that encodes alpha channel transparency into the latent manifold of a pretrained latent diffusion model. It preserves the production-ready quality of the large diffusion model by regulating the added transparency as a latent offset with minimal changes to the original latent distribution of the pretrained model. In this way, any latent diffusion model can be converted into a transparent image generator by finetuning it with the adjusted latent space. We train the model with 1M transparent image layer pairs collected using a human-in-the-loop collection scheme. We show that latent transparency can be applied to different open source image generators, or be adapted to various conditional control systems to achieve applications like foreground/background-conditioned layer generation, joint layer generation, structural control of layer contents, etc. A user study finds that in most cases (97%) users prefer our natively generated transparent content over previous ad-hoc solutions such as generating and then matting. Users also report the quality of our generated transparent images is comparable to real commercial transparent assets like Adobe Stock.",
      "provider": "Silaych Corporation",
      "input": "input",
      "outpt": "output",
      "stared": 100,
      "gitlink": "#",
      "tags":[
        "image classification",
        "object detection",
        "semantic segmentation"
      ],
      "image": "https://picsum.photos/id/237/200/300",
      "version": "1.0"
    },
    {
      "id": 2,
      "name": "Xception",
      "category": "Category 2",
      "shortdescription": "Xception is a Convolutional networks (ConvNets) in visual recognition developped by Francois Chollet from Google Inc. in 2016 (References: https://arxiv.org/abs/1610.02357). Xception has been trained on the ImageNet ILSVRC-2014.",
      "longdescription": "DescriptionXception is a Convolutional networks (ConvNets) in visual recognition developped by Francois Chollet from Google Inc. in 2016 (References: https://arxiv.org/abs/1610.02357). Xception has been trained on the ImageNet ILSVRC-2014 (http://image-net.org/challenges/LSVRC/2014/index) images database and is able to classify images from 1,000 different categories from spider mite to motor scooter. Xception outperforms Inception V3 on image classification tasks. The model architecture of Xception belongs to the Inception-style models family with so called Inception module which departs from earlier VGG-style networks. Inception modules are similar to classic convolutions (i.e. feature extractors), however they are capable of learning richer representations with less parameters at lower computational cost. The weights were released under the MIT license.",
      "provider": "Provider B",
      "input": "input",
      "outpt": "output",
      "stared": 200,
      "gitlink": "#",
      "tags":[
        "image classification",
        "object detection",
        "semantic segmentation"
      ],
      "image": "https://picsum.photos/id/870/200/300?grayscale&blur=2",
      "version": "1.0"
    
    },
    {
      "id": 3,
      "name": "Generative Adversarial Networks (GANs)",
      "category": "Category 3",
      "shortdescription": "GANs are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework.",
      "longdescription": "Generative Adversarial Networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework. They were introduced by Ian Goodfellow and his colleagues in 2014. This technique can generate photographs that look at least superficially authentic to human observers, having many realistic characteristics. The effectiveness of GANs makes them applicable to a wide variety of tasks, including generating artwork, human faces, and voice synthesis.",
      "provider": "Provider C",
      "input": "input",
      "output": "output",
      "stared": 150,
      "gitlink": "#",
      "tags":[
        "generative models",
        "unsupervised learning",
        "neural networks"
      ],
      "image": "https://picsum.photos/id/1011/200/300",
      "version": "1.0"
    },
    {
      "id": 4,
      "name": "Reinforcement Learning",
      "category": "Category 4",
      "shortdescription": "Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize some notion of cumulative reward.",
      "longdescription": "Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. Reinforcement learning differs from supervised learning in not needing labeled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).",
      "provider": "Provider D",
      "input": "input",
      "output": "output",
      "stared": 120,
      "gitlink": "#",
      "tags":[
        "reinforcement learning",
        "machine learning",
        "artificial intelligence"
      ],
      "image": "https://picsum.photos/id/1025/200/300",
      "version": "1.0"
    },
    {
      "id": 5,
      "name": "Transformer Architecture",
      "category": "Category 5",
      "shortdescription": "The transformer architecture, a type of deep learning model introduced in 2017, has become a standard in natural language processing (NLP) and other sequence-based tasks.",
      "longdescription": "The transformer architecture, a type of deep learning model introduced in 2017, has become a standard in natural language processing (NLP) and other sequence-based tasks. Unlike recurrent neural networks (RNNs), which process inputs sequentially, transformers process entire sequences of data at once. This parallel processing capability, along with self-attention mechanisms, allows transformers to capture long-range dependencies more effectively than RNNs. Transformers have achieved state-of-the-art results in a variety of NLP tasks, including language translation, text generation, and sentiment analysis.",
      "provider": "Provider E",
      "input": "input",
      "output": "output",
      "stared": 180,
      "gitlink": "#",
      "tags":[
        "transformer",
        "NLP",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1035/200/300",
      "version": "1.0"
    },
    {
      "id": 6,
      "name": "Capsule Networks",
      "category": "Category 6",
      "shortdescription": "Capsule Networks are a type of artificial neural network designed to better model hierarchical relationships.",
      "longdescription": "Capsule Networks are a type of artificial neural network designed to better model hierarchical relationships. They were introduced by Geoffrey Hinton and his colleagues in 2017 as a potential replacement for convolutional neural networks (CNNs) in tasks such as image recognition. Capsule networks aim to address some of the limitations of CNNs, such as their inability to handle variations in pose, deformation, and viewpoint. By explicitly modeling relationships between parts of an object, capsule networks can achieve greater robustness and generalization.",
      "provider": "Provider F",
      "input": "input",
      "output": "output",
      "stared": 90,
      "gitlink": "#",
      "tags":[
        "capsule networks",
        "image recognition",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1041/200/300",
      "version": "1.0"
    }
  ],
  "mostViewed" :[
    {
      "id": 7,
      "name": "Graph Neural Networks",
      "category": "Category 7",
      "shortdescription": "Graph neural networks (GNNs) are a class of artificial neural networks designed to process data represented as graphs.",
      "longdescription": "Graph neural networks (GNNs) are a class of artificial neural networks designed to process data represented as graphs. They have gained popularity in recent years due to their ability to effectively model relational data, such as social networks, citation networks, and molecular structures. GNNs operate by passing messages between nodes in a graph, allowing them to capture complex dependencies and relationships. They have achieved state-of-the-art results in tasks such as node classification, link prediction, and graph generation.",
      "provider": "Provider G",
      "input": "input",
      "output": "output",
      "stared": 150,
      "gitlink": "#",
      "tags":[
        "graph neural networks",
        "graph data",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1047/200/300",
      "version": "1.0"
    },
    {
      "id": 8,
      "name": "BERT (Bidirectional Encoder Representations from Transformers)",
      "category": "Category 8",
      "shortdescription": "BERT is a pre-trained natural language processing model developed by Google.",
      "longdescription": "BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained natural language processing model developed by Google. It was introduced in 2018 and has since become a widely used model in the NLP community. BERT is trained on large amounts of text data using a self-supervised learning objective, allowing it to capture rich contextual information. It has achieved state-of-the-art results in a variety of NLP tasks, including question answering, sentiment analysis, and named entity recognition.",
      "provider": "Provider H",
      "input": "input",
      "output": "output",
      "stared": 220,
      "gitlink": "#",
      "tags":[
        "BERT",
        "NLP",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1055/200/300",
      "version": "1.0"
    },
    {
      "id": 9,
      "name": "Variational Autoencoders (VAEs)",
      "category": "Category 9",
      "shortdescription": "Variational autoencoders (VAEs) are a class of generative models based on neural networks.",
      "longdescription": "Variational autoencoders (VAEs) are a class of generative models based on neural networks. They were introduced by Diederik P. Kingma and Max Welling in 2013 as a way to learn probabilistic latent representations of data. VAEs consist of an encoder network, which maps input data to a probability distribution in latent space, and a decoder network, which maps samples from the latent space back to the data space. By training the model to reconstruct input data while also regularizing the distribution of latent variables, VAEs can learn compact and meaningful representations of complex data.",
      "provider": "Provider I",
      "input": "input",
      "output": "output",
      "stared": 180,
      "gitlink": "#",
      "tags":[
        "variational autoencoders",
        "generative models",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1065/200/300",
      "version": "1.0"
    },
    {
      "id": 10,
      "name": "ResNet (Residual Neural Network)",
      "category": "Category 10",
      "shortdescription": "ResNet is a deep residual learning framework developed by Microsoft Research.",
      "longdescription": "ResNet (Residual Neural Network) is a deep learning framework developed by Microsoft Research. It was introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun in 2015 and has since become a widely used model architecture in computer vision tasks. ResNet introduces skip connections, or shortcuts, that allow gradients to flow more easily during training, alleviating the vanishing gradient problem. This enables the training of very deep neural networks with hundreds or even thousands of layers. ResNet has achieved state-of-the-art results in image classification, object detection, and image segmentation.",
      "provider": "Provider J",
      "input": "input",
      "output": "output",
      "stared": 250,
      "gitlink": "#",
      "tags":[
        "ResNet",
        "deep learning",
        "computer vision"
      ],
      "image": "https://picsum.photos/id/1075/200/300",
      "version": "1.0"
    },
    {
      "id": 11,
      "name": "Word2Vec",
      "category": "Category 11",
      "shortdescription": "Word2Vec is a popular technique for word embedding developed by researchers at Google.",
      "longdescription": "Word2Vec is a popular technique for word embedding developed by researchers at Google. It was introduced by Tomas Mikolov and his colleagues in 2013 as a way to learn distributed representations of words in a continuous vector space. Word2Vec uses a shallow neural network to predict the context of a word given its surrounding words or vice versa. By training the model on large amounts of text data, Word2Vec can learn semantic similarities between words, allowing for tasks such as word similarity calculation, word analogy completion, and text classification.",
      "provider": "Provider K",
      "input": "input",
      "output": "output",
      "stared": 180,
      "gitlink": "#",
      "tags":[
        "Word2Vec",
        "word embedding",
        "NLP"
      ],
      "image": "https://picsum.photos/id/1085/200/300",
      "version": "1.0"
    },
    {
      "id": 12,
      "name": "Deep Q-Networks (DQN)",
      "category": "Category 12",
      "shortdescription": "Deep Q-Networks (DQN) are a class of deep reinforcement learning algorithms.",
      "longdescription": "Deep Q-Networks (DQN) are a class of deep reinforcement learning algorithms. They were introduced by DeepMind in 2015 as a way to learn to play Atari games directly from raw pixel inputs. DQN combines deep learning techniques with Q-learning, a classic reinforcement learning algorithm, to approximate the optimal action-value function. By training a neural network to predict the expected future rewards of taking different actions in different states, DQN agents can learn to play a wide range of video games at human or superhuman levels.",
      "provider": "Provider L",
      "input": "input",
      "output": "output",
      "stared": 200,
      "gitlink": "#",
      "tags":[
        "Deep Q-Networks",
        "reinforcement learning",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1095/200/300",
      "version": "1.0"
    },
    {
      "id": 13,
      "name": "Generative Pre-trained Transformer 3 (GPT-3)",
      "category": "Category 13",
      "shortdescription": "GPT-3 is a state-of-the-art language processing model developed by OpenAI.",
      "longdescription": "Generative Pre-trained Transformer 3 (GPT-3) is a state-of-the-art language processing model developed by OpenAI. It is the third iteration in the GPT series and is one of the largest and most powerful language models to date. GPT-3 has been trained on a diverse range of internet text and can generate human-like text in a variety of styles and formats. It has demonstrated strong performance on a wide range of natural language understanding and generation tasks, including text completion, translation, summarization, and question answering.",
      "provider": "Provider M",
      "input": "input",
      "output": "output",
      "stared": 300,
      "gitlink": "#",
      "tags":[
        "GPT-3",
        "natural language processing",
        "language model"
      ],
      "image": "https://picsum.photos/id/1105/200/300",
      "version": "1.0"
    },
    {
      "id": 14,
      "name": "YOLO (You Only Look Once)",
      "category": "Category 14",
      "shortdescription": "YOLO is an object detection system that can detect objects in real-time.",
      "longdescription": "YOLO (You Only Look Once) is an object detection system that can detect objects in real-time. It was introduced by Joseph Redmon and Santosh Divvala in 2016 and has since become a popular choice for real-time object detection tasks. YOLO operates by dividing images into a grid and predicting bounding boxes and class probabilities for each grid cell. This allows YOLO to detect multiple objects in an image with a single forward pass of a neural network. YOLO has been used in a variety of applications, including autonomous vehicles, surveillance systems, and augmented reality.",
      "provider": "Provider N",
      "input": "input",
      "output": "output",
      "stared": 250,
      "gitlink": "#",
      "tags":[
        "YOLO",
        "object detection",
        "real-time"
      ],
      "image": "https://picsum.photos/id/1115/200/300",
      "version": "1.0"
    },
    {
      "id": 15,
      "name": "CycleGAN",
      "category": "Category 15",
      "shortdescription": "CycleGAN is a neural network architecture for image-to-image translation tasks.",
      "longdescription": "CycleGAN is a neural network architecture for image-to-image translation tasks. It was introduced by Jun-Yan Zhu et al. in 2017 as a way to learn mappings between two domains without requiring paired training data. CycleGAN consists of two generator networks and two discriminator networks, which are trained adversarially to learn mappings from one domain to another and back again. This allows CycleGAN to perform tasks such as style transfer, object transfiguration, and season transfer without the need for paired examples. CycleGAN has been used in a variety of applications, including artistic style transfer, photo enhancement, and domain adaptation.",
      "provider": "Provider O",
      "input": "input",
      "output": "output",
      "stared": 200,
      "gitlink": "#",
      "tags":[
        "CycleGAN",
        "image translation",
        "neural networks"
      ],
      "image": "https://picsum.photos/id/1125/200/300",
      "version": "1.0"
    }
  ],
  "mostStarred" : [
    {
      "id": 6,
      "name": "Capsule Networks",
      "category": "Category 6",
      "shortdescription": "Capsule Networks are a type of artificial neural network designed to better model hierarchical relationships.",
      "longdescription": "Capsule Networks are a type of artificial neural network designed to better model hierarchical relationships. They were introduced by Geoffrey Hinton and his colleagues in 2017 as a potential replacement for convolutional neural networks (CNNs) in tasks such as image recognition. Capsule networks aim to address some of the limitations of CNNs, such as their inability to handle variations in pose, deformation, and viewpoint. By explicitly modeling relationships between parts of an object, capsule networks can achieve greater robustness and generalization.",
      "provider": "Provider F",
      "input": "input",
      "output": "output",
      "stared": 6749,
      "gitlink": "#",
      "tags":[
        "capsule networks",
        "image recognition",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1041/200/300",
      "version": "1.0"
    },
    {
      "id": 12,
      "name": "Deep Q-Networks (DQN)",
      "category": "Category 12",
      "shortdescription": "Deep Q-Networks (DQN) are a class of deep reinforcement learning algorithms.",
      "longdescription": "Deep Q-Networks (DQN) are a class of deep reinforcement learning algorithms. They were introduced by DeepMind in 2015 as a way to learn to play Atari games directly from raw pixel inputs. DQN combines deep learning techniques with Q-learning, a classic reinforcement learning algorithm, to approximate the optimal action-value function. By training a neural network to predict the expected future rewards of taking different actions in different states, DQN agents can learn to play a wide range of video games at human or superhuman levels.",
      "provider": "Provider L",
      "input": "input",
      "output": "output",
      "stared": 1603,
      "gitlink": "#",
      "tags":[
        "Deep Q-Networks",
        "reinforcement learning",
        "deep learning"
      ],
      "image": "https://picsum.photos/id/1095/200/300",
      "version": "1.0"
    },
    {
      "id": 13,
      "name": "Generative Pre-trained Transformer 3 (GPT-3)",
      "category": "Category 13",
      "shortdescription": "GPT-3 is a state-of-the-art language processing model developed by OpenAI.",
      "longdescription": "Generative Pre-trained Transformer 3 (GPT-3) is a state-of-the-art language processing model developed by OpenAI. It is the third iteration in the GPT series and is one of the largest and most powerful language models to date. GPT-3 has been trained on a diverse range of internet text and can generate human-like text in a variety of styles and formats. It has demonstrated strong performance on a wide range of natural language understanding and generation tasks, including text completion, translation, summarization, and question answering.",
      "provider": "Provider M",
      "input": "input",
      "output": "output",
      "stared": 1510,
      "gitlink": "#",
      "tags":[
        "GPT-3",
        "natural language processing",
        "language model"
      ],
      "image": "https://picsum.photos/id/1105/200/300",
      "version": "1.0"
    }

  ]
  
}